// Auto-generated file - do not edit manually
// Run 'npm run generate-writings' to regenerate

export const writings = [
  {
    "id": "the-bell-jar",
    "slug": "the-bell-jar",
    "title": "Under the Fig Tree",
    "excerpt": "To all the different paths in life",
    "date": "2025-07-21",
    "category": "literature",
    "readTimeMinutes": 3,
    "content": [
      "#### \"I saw my life branching out before me like the green fig tree in the story. From the tip of every branch, like a fat purple fig, a wonderful future beckoned and winked. One fig was a husband and a happy home and children, and another fig was a famous poet and another fig was a brilliant professor, and another fig was Ee Gee, the amazing editor, and another fig was Europe and Africa and South America, and another fig was Constantin and Socrates and Attila and a pack of other lovers with queer names and offbeat professions, and another fig was an Olympic lady crew champion, and beyond and above these figs were many more figs I couldn't quite make out. I saw myself sitting in the crotch of this fig tree, starving to death, just because I couldn't make up my mind which of the figs I would choose. I wanted each and every one of them, but choosing one meant losing all the rest, and, as I sat there, unable to decide, the figs began to wrinkle and go black, and, one by one, they plopped to the ground at my feet.”",
      "― Sylvia Plath",
      "## My thoughts \nA beautiful piece of literature, for something as saddening as wasting opportunities in the face of indecision.",
      "> \"I can never be all the people I want, and live all the lives I want. And why do I want? I want to live and feel all of the shades, tones and variations of mental and physical experience possible in my life. And I am horribly limited.\"",
      "I am someone who wants to do many things. A person of many interests―with each interest consuming me―just at different points in time. It was something I used to see as a flaw. In fact, it may indeed be a flaw, depending on who you ask. When I was younger I only focused on interests that makes sense, those that would be useful in the long run... Interests that have a high ROI, if you will.",
      "Personal Finance, Real Estate, Coding.",
      "I tried to absorb as much knowledge as I can on these topics. I solely pursued them and brushed off anything else that interested me but '*didn't make sense*'. However, as much as I loved learning about these, restricting myself to only these interests eventually took a toll. I no longer saw them as something that I found joy in learning about. i gradually saw them as a chore. This is the turning point in which I decided to branch out. Since then, I have explored a multitude of other random interests:",
      "Reading, Gardening, Sketching, Volleyball, Hiking, Skiing, Philosophy, Psychology, Volunteering, Tutoring and now, Writing.",
      "I pursued a lot of things that do not necessarily relate to each other(I think my younger self would be confused and wonder what went wrong. oops) but I took solace in that I do not have to limit myself to just one purpose, one talent, one hobby. I allowed myself to have a variety of interests, each of them as meaningful at the time I have them. Through these little explorations, I learnt more about myself. I found that I enjoy creating things, I enjoy the outdoors, travelling and adventure. I learnt that I found joy in giving back to society, that I do my best work when I am inspired by this purpose.",
      "These varied interests spilled into my career as well. Within tech, I found myself drawn to UI/UX, Front End Development, Big Data, Model Development, and Artificial Intelligence. Knowing myself, I will try to learn all these given the time. Problem is, I do not have much time in school left. Much like in the poem, I found myself sitting at the crux of the many paths I can take. Undecided, I prolong my decision and tell myself I will keep exploring each of these paths and make a better informed decision in time. But what if that time doesn't come? What if I take so long to decide I waste my opportunities?",
      "I actually brought this up to my mentors, and I received two very different, yet equally valueable, pieces of advice.",
      "One encouraged me to pursue the career path I **currently** have the most interest in, while cautioning against overspecialisation. His advice was to commit, but with flexibility. He said that in whichever field I choose, leave room to explore the surrounding fields, so that I can easily pivot if need be.",
      "One told me not to get so caught up with career choices. He said career switches are normal, that it takes time to explore such a vast field and interests change all the time.",
      "> \"You do not need to have your entire career plan figured out by the time you graduate.\"",
      "Instead, he advised me to look at the bigger picture, to ask myself what kind of life I want to live, and how my career would fit into that.",
      "Two very wildly different pieces of advice, yet both rang true in their own ways. It gave me comfort in that there is no one right singular answer, no one right singular way to do things. Choosing one path does not mean abandoning the other entirely.",
      "I may not know which fig to choose yet, but I trust that when the time comes to make a decision, I will make the most out of what I know, and figure it out from there on.",
      "How about you, which figs are you still hesitating to reach out for?"
    ],
    "markdown": "#### \"I saw my life branching out before me like the green fig tree in the story. From the tip of every branch, like a fat purple fig, a wonderful future beckoned and winked. One fig was a husband and a happy home and children, and another fig was a famous poet and another fig was a brilliant professor, and another fig was Ee Gee, the amazing editor, and another fig was Europe and Africa and South America, and another fig was Constantin and Socrates and Attila and a pack of other lovers with queer names and offbeat professions, and another fig was an Olympic lady crew champion, and beyond and above these figs were many more figs I couldn't quite make out. I saw myself sitting in the crotch of this fig tree, starving to death, just because I couldn't make up my mind which of the figs I would choose. I wanted each and every one of them, but choosing one meant losing all the rest, and, as I sat there, unable to decide, the figs began to wrinkle and go black, and, one by one, they plopped to the ground at my feet.”\n\n― Sylvia Plath\n\n## My thoughts \nA beautiful piece of literature, for something as saddening as wasting opportunities in the face of indecision. \n\n> \"I can never be all the people I want, and live all the lives I want. And why do I want? I want to live and feel all of the shades, tones and variations of mental and physical experience possible in my life. And I am horribly limited.\" \n\nI am someone who wants to do many things. A person of many interests―with each interest consuming me―just at different points in time. It was something I used to see as a flaw. In fact, it may indeed be a flaw, depending on who you ask. When I was younger I only focused on interests that makes sense, those that would be useful in the long run... Interests that have a high ROI, if you will.\n\nPersonal Finance, Real Estate, Coding. \n\nI tried to absorb as much knowledge as I can on these topics. I solely pursued them and brushed off anything else that interested me but '*didn't make sense*'. However, as much as I loved learning about these, restricting myself to only these interests eventually took a toll. I no longer saw them as something that I found joy in learning about. i gradually saw them as a chore. This is the turning point in which I decided to branch out. Since then, I have explored a multitude of other random interests:\n\nReading, Gardening, Sketching, Volleyball, Hiking, Skiing, Philosophy, Psychology, Volunteering, Tutoring and now, Writing. \n\nI pursued a lot of things that do not necessarily relate to each other(I think my younger self would be confused and wonder what went wrong. oops) but I took solace in that I do not have to limit myself to just one purpose, one talent, one hobby. I allowed myself to have a variety of interests, each of them as meaningful at the time I have them. Through these little explorations, I learnt more about myself. I found that I enjoy creating things, I enjoy the outdoors, travelling and adventure. I learnt that I found joy in giving back to society, that I do my best work when I am inspired by this purpose. \n\nThese varied interests spilled into my career as well. Within tech, I found myself drawn to UI/UX, Front End Development, Big Data, Model Development, and Artificial Intelligence. Knowing myself, I will try to learn all these given the time. Problem is, I do not have much time in school left. Much like in the poem, I found myself sitting at the crux of the many paths I can take. Undecided, I prolong my decision and tell myself I will keep exploring each of these paths and make a better informed decision in time. But what if that time doesn't come? What if I take so long to decide I waste my opportunities?\n\nI actually brought this up to my mentors, and I received two very different, yet equally valueable, pieces of advice. \n\nOne encouraged me to pursue the career path I **currently** have the most interest in, while cautioning against overspecialisation. His advice was to commit, but with flexibility. He said that in whichever field I choose, leave room to explore the surrounding fields, so that I can easily pivot if need be. \n\nOne told me not to get so caught up with career choices. He said career switches are normal, that it takes time to explore such a vast field and interests change all the time. \n\n> \"You do not need to have your entire career plan figured out by the time you graduate.\" \n\nInstead, he advised me to look at the bigger picture, to ask myself what kind of life I want to live, and how my career would fit into that. \n\nTwo very wildly different pieces of advice, yet both rang true in their own ways. It gave me comfort in that there is no one right singular answer, no one right singular way to do things. Choosing one path does not mean abandoning the other entirely. \n\nI may not know which fig to choose yet, but I trust that when the time comes to make a decision, I will make the most out of what I know, and figure it out from there on. \n\nHow about you, which figs are you still hesitating to reach out for?",
    "html": "<h4>&quot;I saw my life branching out before me like the green fig tree in the story. From the tip of every branch, like a fat purple fig, a wonderful future beckoned and winked. One fig was a husband and a happy home and children, and another fig was a famous poet and another fig was a brilliant professor, and another fig was Ee Gee, the amazing editor, and another fig was Europe and Africa and South America, and another fig was Constantin and Socrates and Attila and a pack of other lovers with queer names and offbeat professions, and another fig was an Olympic lady crew champion, and beyond and above these figs were many more figs I couldn&#39;t quite make out. I saw myself sitting in the crotch of this fig tree, starving to death, just because I couldn&#39;t make up my mind which of the figs I would choose. I wanted each and every one of them, but choosing one meant losing all the rest, and, as I sat there, unable to decide, the figs began to wrinkle and go black, and, one by one, they plopped to the ground at my feet.”</h4>\n<p>― Sylvia Plath</p>\n<h2>My thoughts </h2>\n<p>A beautiful piece of literature, for something as saddening as wasting opportunities in the face of indecision.</p>\n<blockquote><p>&quot;I can never be all the people I want, and live all the lives I want. And why do I want? I want to live and feel all of the shades, tones and variations of mental and physical experience possible in my life. And I am horribly limited.&quot; </p></blockquote>\n<p>I am someone who wants to do many things. A person of many interests―with each interest consuming me―just at different points in time. It was something I used to see as a flaw. In fact, it may indeed be a flaw, depending on who you ask. When I was younger I only focused on interests that makes sense, those that would be useful in the long run... Interests that have a high ROI, if you will.</p>\n<p>Personal Finance, Real Estate, Coding.</p>\n<p>I tried to absorb as much knowledge as I can on these topics. I solely pursued them and brushed off anything else that interested me but &#39;<em>didn&#39;t make sense</em>&#39;. However, as much as I loved learning about these, restricting myself to only these interests eventually took a toll. I no longer saw them as something that I found joy in learning about. i gradually saw them as a chore. This is the turning point in which I decided to branch out. Since then, I have explored a multitude of other random interests:</p>\n<p>Reading, Gardening, Sketching, Volleyball, Hiking, Skiing, Philosophy, Psychology, Volunteering, Tutoring and now, Writing.</p>\n<p>I pursued a lot of things that do not necessarily relate to each other(I think my younger self would be confused and wonder what went wrong. oops) but I took solace in that I do not have to limit myself to just one purpose, one talent, one hobby. I allowed myself to have a variety of interests, each of them as meaningful at the time I have them. Through these little explorations, I learnt more about myself. I found that I enjoy creating things, I enjoy the outdoors, travelling and adventure. I learnt that I found joy in giving back to society, that I do my best work when I am inspired by this purpose.</p>\n<p>These varied interests spilled into my career as well. Within tech, I found myself drawn to UI/UX, Front End Development, Big Data, Model Development, and Artificial Intelligence. Knowing myself, I will try to learn all these given the time. Problem is, I do not have much time in school left. Much like in the poem, I found myself sitting at the crux of the many paths I can take. Undecided, I prolong my decision and tell myself I will keep exploring each of these paths and make a better informed decision in time. But what if that time doesn&#39;t come? What if I take so long to decide I waste my opportunities?</p>\n<p>I actually brought this up to my mentors, and I received two very different, yet equally valueable, pieces of advice.</p>\n<p>One encouraged me to pursue the career path I <strong>currently</strong> have the most interest in, while cautioning against overspecialisation. His advice was to commit, but with flexibility. He said that in whichever field I choose, leave room to explore the surrounding fields, so that I can easily pivot if need be.</p>\n<p>One told me not to get so caught up with career choices. He said career switches are normal, that it takes time to explore such a vast field and interests change all the time.</p>\n<blockquote><p>&quot;You do not need to have your entire career plan figured out by the time you graduate.&quot; </p></blockquote>\n<p>Instead, he advised me to look at the bigger picture, to ask myself what kind of life I want to live, and how my career would fit into that.</p>\n<p>Two very wildly different pieces of advice, yet both rang true in their own ways. It gave me comfort in that there is no one right singular answer, no one right singular way to do things. Choosing one path does not mean abandoning the other entirely.</p>\n<p>I may not know which fig to choose yet, but I trust that when the time comes to make a decision, I will make the most out of what I know, and figure it out from there on.</p>\n<p>How about you, which figs are you still hesitating to reach out for?</p>"
  },
  {
    "id": "attention-is-all-you-need",
    "slug": "attention-is-all-you-need",
    "title": "Attention is all you need",
    "excerpt": "My notes on the Transformers Architecture",
    "date": "2025-06-18",
    "category": "tech",
    "readTimeMinutes": 6,
    "content": [
      "# The Transformers Architecture \n\nIf you've been anywhere near AI in the last few years, you've probably heard about Transformers. No, not the robot movie kind (though they were pretty cool). The architecture comes from a 2017 research paper titled *\"Attention Is All You Need\"*, and it spurred frenzy in the AI world.\n\nSo, why was it groundbreaking? Let's break it down.\n\n## Traditional Transduction models: RNNs and CNNs\nBefore Transformers, traditional transduction sequence models relied on Recurrent Neural Networks [(RNN)](https://www.geeksforgeeks.org/machine-learning/introduction-to-recurrent-neural-network/) or Convolutional Neural Networks [(CNN)](https://www.geeksforgeeks.org/machine-learning/introduction-convolution-neural-network/). \n\n*Transduction models*: Takes one form of sequential data and transforms it to another sequence. Kind of like a translator/convertor.\n> Example: \"Hello, how are you?\" (English) -> \"Hola, ¿cómo estás?\" (Spanish)\n\n**RNNs** read one word at a time, keeping memory of what came before. Like reading a book one word at a time, trying to remember every single detail from the beginning. By the time you hit page 200, remembering exactly what was on page 1 is… hard. This is coined the [Vanishing Gradient Problem](https://www.geeksforgeeks.org/deep-learning/vanishing-and-exploding-gradients-problems-in-deep-learning/), long-range dependencies get fuzzy.\n\n**CNNs** were better at spotting local features, like edges in an image, but they still looked at things in \"windows.\" Like examining a giant painting through a small cut-out frame: you see details, but it's hard to appreciate the whole masterpiece at once.\n\nBoth had another big drawback in that they processed information **sequentially**, making training these models a slow, painstaking process.\n\n## The Saving Grace: Transformers\n\nTransformers flipped the script. No recurrence. No convolutions. But **Attention Mechanisms**\n\nInstead of trudging word by word, Transformers look at all the words at once. They can connect \"cat\" in the first sentence to \"it\" 50 words later instantly. This parallelism not only speeds up training but also makes it way easier to capture long-range relationships.\n\nIn short:\n\n- **RNNs** were like reading word by word and struggling with memory\n- **CNNs** were like peeking at a painting through small little frames  \n- **Transformers** let you see everything *at once*\n\n## How Attention Mechanisms Work (Without Too Much Math)\n\nThe general idea here is that every word asks: *\"Which other words in this sentence matter the most to me?\"*. It then takes into account the relative importance of every other word and embeds this information into its own numeric representation. \n\nAttention is derived from three important variables: Queries, Keys and Values. \n\nThe Q/K/V concept is analogous to retrieval systems. For example, when you search for videos on YouTube, the search engine will map your **query** (text in the search bar) against a set of **keys** (video title, description, etc.) associated with videos in the database, then present you the best matched videos (**values**) [(useful discussion)](https://stats.stackexchange.com/questions/421935/what-exactly-are-keys-queries-and-values-in-attention-mechanisms)\n\nIn the context of Transformers:\n- **Query (Q)**: the search question that the current word is asking\n- **Key (K)**: the searchable attributes that each word can be matched against  \n- **Value (V)**: the actual information content that gets retrieved and mixed together\n\n## Example: \"Tom eats fish\" (More Math Involved Here)\nAttention can be calculated using the following formula:\n![Project image](/writings/attention_formula.png)\n\nLet's zoom into how attention updates the word \"eats\" using sample values. \n\n(Q) Query (\"eats\" asks \"who do I relate to?\"): Let Q=1.0\n\n(K) Keys: Tom=2.0, eats=0.1, fish=1.5 -> [2.0,0.1,1.5]\n\n(V) Values:\n- Tom = [1, 0] (a subject-y feature)\n- eats = [0, 0] (self, less useful here)\n- fish = [0, 1] (an object-y feature)\n\n### Calculating Similarity Scores, Qk \nWe use the key-query dot product to understand how relevant two words are to each other. A bigger dot product = more relevant.\n\nQk = [2.0, 0.1, 1.5]\n\n### Scaling\nIf the vectors are high-dimensional, dot products can get really large, which can mess up the the values in the next step. Numbers are scaled to keep them in a nice range.\n\nAfter scaling (assume scaling function=1): [2.0, 0.1, 1.5]\n\n### Softmax Function \nNow we take all those similarity scores and run them through a softmax function. The point of this softmax function is to calculate the **attention weights** amongst the words.\n\nAfter softmax: [0.57, 0.08, 0.35]\n\n### Interpretation \nConsidering the word \"eats\", we can define how much attention it should pay to the other words in the sentence. \n- “eats” pays 57% attention to “Tom,” \n- \"eats\" pays 35% attention to “fish,” \n- \"eats\" pays 8% attention to itself\n\n### Weighted Sum of Values (V)\nFinally, we apply these attention weights to V, which hold the actual information from each word. \n- \"Tom\" V = [1, 0] (subject feature)\n- \"eats\" V = [0, 0] (verb feature)\n- \"fish\" V = [0, 1] (object feature)\nWeighted sum = 0.57·[1,0] + 0.35·[0,1] ≈ [0.57, 0.35]\n\n**This new vector becomes the updated representation of “eats”. Notice how these numbers are a reprentation of the word's relationship to both \"Tom\" and \"fish\"**\n\n### Multi-Head Attention \nInstead of doing the entire process above just once, Transformers do it in parallel across multiple “heads” with different learned Q/K/V projections. Each head can capture a different type of relationship. With several heads running in parallel.\n\nOne head might focus on **subject–verb** links. Another might look at **object–verb** links.  \n\nThese heads get combined afterwards. An analogy is like having a group of friends watching the same movie concurrently. One focuses on the plot, another on the characters and maybe another on the dialogues. Put all of their knowledge together and you get a much more intricate understanding of the entire movie.\n\n## Why This Was a Big Deal\n\nThe results spoke for themselves:\n\n- On English-to-German translation, Transformers set a new state-of-the-art with a **BLEU score of 28.4**\n- The model generalised well beyond translation, it was able to perform well in tasks like English parsing too\n\nBy solving sequence problems with attention, Transformers opened the door to models like **BERT**, **GPT**, and all the large language models we use today. That's why this one paper is cited everywhere... it marked the beginning of the modern AI wave. So, next time you hear *\"attention is all you need,\"* know it's not just a catchy phrase. It's also the research paper that revolutionised the AI landscape. \n\nAnd that's why the Transformers architecture *transformed* (get it) the tech world as we know it today."
    ],
    "markdown": "# The Transformers Architecture \r\n\r\nIf you've been anywhere near AI in the last few years, you've probably heard about Transformers. No, not the robot movie kind (though they were pretty cool). The architecture comes from a 2017 research paper titled *\"Attention Is All You Need\"*, and it spurred frenzy in the AI world.\r\n\r\nSo, why was it groundbreaking? Let's break it down.\r\n\r\n## Traditional Transduction models: RNNs and CNNs\r\nBefore Transformers, traditional transduction sequence models relied on Recurrent Neural Networks [(RNN)](https://www.geeksforgeeks.org/machine-learning/introduction-to-recurrent-neural-network/) or Convolutional Neural Networks [(CNN)](https://www.geeksforgeeks.org/machine-learning/introduction-convolution-neural-network/). \r\n\r\n*Transduction models*: Takes one form of sequential data and transforms it to another sequence. Kind of like a translator/convertor.\r\n> Example: \"Hello, how are you?\" (English) -> \"Hola, ¿cómo estás?\" (Spanish)\r\n\r\n**RNNs** read one word at a time, keeping memory of what came before. Like reading a book one word at a time, trying to remember every single detail from the beginning. By the time you hit page 200, remembering exactly what was on page 1 is… hard. This is coined the [Vanishing Gradient Problem](https://www.geeksforgeeks.org/deep-learning/vanishing-and-exploding-gradients-problems-in-deep-learning/), long-range dependencies get fuzzy.\r\n\r\n**CNNs** were better at spotting local features, like edges in an image, but they still looked at things in \"windows.\" Like examining a giant painting through a small cut-out frame: you see details, but it's hard to appreciate the whole masterpiece at once.\r\n\r\nBoth had another big drawback in that they processed information **sequentially**, making training these models a slow, painstaking process.\r\n\r\n## The Saving Grace: Transformers\r\n\r\nTransformers flipped the script. No recurrence. No convolutions. But **Attention Mechanisms**\r\n\r\nInstead of trudging word by word, Transformers look at all the words at once. They can connect \"cat\" in the first sentence to \"it\" 50 words later instantly. This parallelism not only speeds up training but also makes it way easier to capture long-range relationships.\r\n\r\nIn short:\r\n\r\n- **RNNs** were like reading word by word and struggling with memory\r\n- **CNNs** were like peeking at a painting through small little frames  \r\n- **Transformers** let you see everything *at once*\r\n\r\n## How Attention Mechanisms Work (Without Too Much Math)\r\n\r\nThe general idea here is that every word asks: *\"Which other words in this sentence matter the most to me?\"*. It then takes into account the relative importance of every other word and embeds this information into its own numeric representation. \r\n\r\nAttention is derived from three important variables: Queries, Keys and Values. \r\n\r\nThe Q/K/V concept is analogous to retrieval systems. For example, when you search for videos on YouTube, the search engine will map your **query** (text in the search bar) against a set of **keys** (video title, description, etc.) associated with videos in the database, then present you the best matched videos (**values**) [(useful discussion)](https://stats.stackexchange.com/questions/421935/what-exactly-are-keys-queries-and-values-in-attention-mechanisms)\r\n\r\nIn the context of Transformers:\r\n- **Query (Q)**: the search question that the current word is asking\r\n- **Key (K)**: the searchable attributes that each word can be matched against  \r\n- **Value (V)**: the actual information content that gets retrieved and mixed together\r\n\r\n## Example: \"Tom eats fish\" (More Math Involved Here)\r\nAttention can be calculated using the following formula:\r\n![Project image](/writings/attention_formula.png)\r\n\r\nLet's zoom into how attention updates the word \"eats\" using sample values. \r\n\r\n(Q) Query (\"eats\" asks \"who do I relate to?\"): Let Q=1.0\r\n\r\n(K) Keys: Tom=2.0, eats=0.1, fish=1.5 -> [2.0,0.1,1.5]\r\n\r\n(V) Values:\r\n- Tom = [1, 0] (a subject-y feature)\r\n- eats = [0, 0] (self, less useful here)\r\n- fish = [0, 1] (an object-y feature)\r\n\r\n### Calculating Similarity Scores, Qk \r\nWe use the key-query dot product to understand how relevant two words are to each other. A bigger dot product = more relevant.\r\n\r\nQk = [2.0, 0.1, 1.5]\r\n\r\n### Scaling\r\nIf the vectors are high-dimensional, dot products can get really large, which can mess up the the values in the next step. Numbers are scaled to keep them in a nice range.\r\n\r\nAfter scaling (assume scaling function=1): [2.0, 0.1, 1.5]\r\n\r\n### Softmax Function \r\nNow we take all those similarity scores and run them through a softmax function. The point of this softmax function is to calculate the **attention weights** amongst the words.\r\n\r\nAfter softmax: [0.57, 0.08, 0.35]\r\n\r\n### Interpretation \r\nConsidering the word \"eats\", we can define how much attention it should pay to the other words in the sentence. \r\n- “eats” pays 57% attention to “Tom,” \r\n- \"eats\" pays 35% attention to “fish,” \r\n- \"eats\" pays 8% attention to itself\r\n\r\n### Weighted Sum of Values (V)\r\nFinally, we apply these attention weights to V, which hold the actual information from each word. \r\n- \"Tom\" V = [1, 0] (subject feature)\r\n- \"eats\" V = [0, 0] (verb feature)\r\n- \"fish\" V = [0, 1] (object feature)\r\nWeighted sum = 0.57·[1,0] + 0.35·[0,1] ≈ [0.57, 0.35]\r\n\r\n**This new vector becomes the updated representation of “eats”. Notice how these numbers are a reprentation of the word's relationship to both \"Tom\" and \"fish\"**\r\n\r\n### Multi-Head Attention \r\nInstead of doing the entire process above just once, Transformers do it in parallel across multiple “heads” with different learned Q/K/V projections. Each head can capture a different type of relationship. With several heads running in parallel.\r\n\r\nOne head might focus on **subject–verb** links. Another might look at **object–verb** links.  \r\n\r\nThese heads get combined afterwards. An analogy is like having a group of friends watching the same movie concurrently. One focuses on the plot, another on the characters and maybe another on the dialogues. Put all of their knowledge together and you get a much more intricate understanding of the entire movie.\r\n\r\n## Why This Was a Big Deal\r\n\r\nThe results spoke for themselves:\r\n\r\n- On English-to-German translation, Transformers set a new state-of-the-art with a **BLEU score of 28.4**\r\n- The model generalised well beyond translation, it was able to perform well in tasks like English parsing too\r\n\r\nBy solving sequence problems with attention, Transformers opened the door to models like **BERT**, **GPT**, and all the large language models we use today. That's why this one paper is cited everywhere... it marked the beginning of the modern AI wave. So, next time you hear *\"attention is all you need,\"* know it's not just a catchy phrase. It's also the research paper that revolutionised the AI landscape. \r\n\r\nAnd that's why the Transformers architecture *transformed* (get it) the tech world as we know it today.",
    "html": "<h1>The Transformers Architecture </h1>\n<p>If you&#39;ve been anywhere near AI in the last few years, you&#39;ve probably heard about Transformers. No, not the robot movie kind (though they were pretty cool). The architecture comes from a 2017 research paper titled <em>&quot;Attention Is All You Need&quot;</em>, and it spurred frenzy in the AI world.</p>\n<p>So, why was it groundbreaking? Let&#39;s break it down.</p>\n<h2>Traditional Transduction models: RNNs and CNNs</h2>\n<p>Before Transformers, traditional transduction sequence models relied on Recurrent Neural Networks <a href=\"https://www.geeksforgeeks.org/machine-learning/introduction-to-recurrent-neural-network/\" rel=\"noopener noreferrer\">(RNN)</a> or Convolutional Neural Networks <a href=\"https://www.geeksforgeeks.org/machine-learning/introduction-convolution-neural-network/\" rel=\"noopener noreferrer\">(CNN)</a>.</p>\n<p><em>Transduction models</em>: Takes one form of sequential data and transforms it to another sequence. Kind of like a translator/convertor.</p>\n<blockquote><p>Example: &quot;Hello, how are you?&quot; (English) -&gt; &quot;Hola, ¿cómo estás?&quot; (Spanish)</p></blockquote>\n<p><strong>RNNs</strong> read one word at a time, keeping memory of what came before. Like reading a book one word at a time, trying to remember every single detail from the beginning. By the time you hit page 200, remembering exactly what was on page 1 is… hard. This is coined the <a href=\"https://www.geeksforgeeks.org/deep-learning/vanishing-and-exploding-gradients-problems-in-deep-learning/\" rel=\"noopener noreferrer\">Vanishing Gradient Problem</a>, long-range dependencies get fuzzy.</p>\n<p><strong>CNNs</strong> were better at spotting local features, like edges in an image, but they still looked at things in &quot;windows.&quot; Like examining a giant painting through a small cut-out frame: you see details, but it&#39;s hard to appreciate the whole masterpiece at once.</p>\n<p>Both had another big drawback in that they processed information <strong>sequentially</strong>, making training these models a slow, painstaking process.</p>\n<h2>The Saving Grace: Transformers</h2>\n<p>Transformers flipped the script. No recurrence. No convolutions. But <strong>Attention Mechanisms</strong></p>\n<p>Instead of trudging word by word, Transformers look at all the words at once. They can connect &quot;cat&quot; in the first sentence to &quot;it&quot; 50 words later instantly. This parallelism not only speeds up training but also makes it way easier to capture long-range relationships.</p>\n<p>In short:</p>\n<ul><li><strong>RNNs</strong> were like reading word by word and struggling with memory</li><li><strong>CNNs</strong> were like peeking at a painting through small little frames</li><li><strong>Transformers</strong> let you see everything <em>at once</em></li></ul>\n<h2>How Attention Mechanisms Work (Without Too Much Math)</h2>\n<p>The general idea here is that every word asks: <em>&quot;Which other words in this sentence matter the most to me?&quot;</em>. It then takes into account the relative importance of every other word and embeds this information into its own numeric representation.</p>\n<p>Attention is derived from three important variables: Queries, Keys and Values.</p>\n<p>The Q/K/V concept is analogous to retrieval systems. For example, when you search for videos on YouTube, the search engine will map your <strong>query</strong> (text in the search bar) against a set of <strong>keys</strong> (video title, description, etc.) associated with videos in the database, then present you the best matched videos (<strong>values</strong>) <a href=\"https://stats.stackexchange.com/questions/421935/what-exactly-are-keys-queries-and-values-in-attention-mechanisms\" rel=\"noopener noreferrer\">(useful discussion)</a></p>\n<p>In the context of Transformers:</p>\n<ul><li><strong>Query (Q)</strong>: the search question that the current word is asking</li><li><strong>Key (K)</strong>: the searchable attributes that each word can be matched against</li><li><strong>Value (V)</strong>: the actual information content that gets retrieved and mixed together</li></ul>\n<h2>Example: &quot;Tom eats fish&quot; (More Math Involved Here)</h2>\n<p>Attention can be calculated using the following formula: <img src=\"/writings/attention_formula.png\" alt=\"Project image\" /></p>\n<p>Let&#39;s zoom into how attention updates the word &quot;eats&quot; using sample values.</p>\n<p>(Q) Query (&quot;eats&quot; asks &quot;who do I relate to?&quot;): Let Q=1.0</p>\n<p>(K) Keys: Tom=2.0, eats=0.1, fish=1.5 -&gt; [2.0,0.1,1.5]</p>\n<p>(V) Values:</p>\n<ul><li>Tom = [1, 0] (a subject-y feature)</li><li>eats = [0, 0] (self, less useful here)</li><li>fish = [0, 1] (an object-y feature)</li></ul>\n<h3>Calculating Similarity Scores, Qk </h3>\n<p>We use the key-query dot product to understand how relevant two words are to each other. A bigger dot product = more relevant.</p>\n<p>Qk = [2.0, 0.1, 1.5]</p>\n<h3>Scaling</h3>\n<p>If the vectors are high-dimensional, dot products can get really large, which can mess up the the values in the next step. Numbers are scaled to keep them in a nice range.</p>\n<p>After scaling (assume scaling function=1): [2.0, 0.1, 1.5]</p>\n<h3>Softmax Function </h3>\n<p>Now we take all those similarity scores and run them through a softmax function. The point of this softmax function is to calculate the <strong>attention weights</strong> amongst the words.</p>\n<p>After softmax: [0.57, 0.08, 0.35]</p>\n<h3>Interpretation </h3>\n<p>Considering the word &quot;eats&quot;, we can define how much attention it should pay to the other words in the sentence.</p>\n<ul><li>“eats” pays 57% attention to “Tom,”</li><li>&quot;eats&quot; pays 35% attention to “fish,”</li><li>&quot;eats&quot; pays 8% attention to itself</li></ul>\n<h3>Weighted Sum of Values (V)</h3>\n<p>Finally, we apply these attention weights to V, which hold the actual information from each word.</p>\n<ul><li>&quot;Tom&quot; V = [1, 0] (subject feature)</li><li>&quot;eats&quot; V = [0, 0] (verb feature)</li><li>&quot;fish&quot; V = [0, 1] (object feature)</li></ul>\n<p>Weighted sum = 0.57·[1,0] + 0.35·[0,1] ≈ [0.57, 0.35]</p>\n<p><strong>This new vector becomes the updated representation of “eats”. Notice how these numbers are a reprentation of the word&#39;s relationship to both &quot;Tom&quot; and &quot;fish&quot;</strong></p>\n<h3>Multi-Head Attention </h3>\n<p>Instead of doing the entire process above just once, Transformers do it in parallel across multiple “heads” with different learned Q/K/V projections. Each head can capture a different type of relationship. With several heads running in parallel.</p>\n<p>One head might focus on <strong>subject–verb</strong> links. Another might look at <strong>object–verb</strong> links.</p>\n<p>These heads get combined afterwards. An analogy is like having a group of friends watching the same movie concurrently. One focuses on the plot, another on the characters and maybe another on the dialogues. Put all of their knowledge together and you get a much more intricate understanding of the entire movie.</p>\n<h2>Why This Was a Big Deal</h2>\n<p>The results spoke for themselves:</p>\n<ul><li>On English-to-German translation, Transformers set a new state-of-the-art with a <strong>BLEU score of 28.4</strong></li><li>The model generalised well beyond translation, it was able to perform well in tasks like English parsing too</li></ul>\n<p>By solving sequence problems with attention, Transformers opened the door to models like <strong>BERT</strong>, <strong>GPT</strong>, and all the large language models we use today. That&#39;s why this one paper is cited everywhere... it marked the beginning of the modern AI wave. So, next time you hear <em>&quot;attention is all you need,&quot;</em> know it&#39;s not just a catchy phrase. It&#39;s also the research paper that revolutionised the AI landscape.</p>\n<p>And that&#39;s why the Transformers architecture <em>transformed</em> (get it) the tech world as we know it today.</p>"
  },
  {
    "id": "khao-yai-thailand",
    "slug": "khao-yai-thailand",
    "title": "Khao Yai, Thailand",
    "excerpt": "My adventures in Khao Yai, and more importantly, the people who gave it meaning",
    "date": "2024-09-12",
    "category": "travels",
    "readTimeMinutes": 5,
    "content": [
      ">\"I-cha!, you know how to play poker mai?\"",
      "My head swivelled to the right.",
      "*I-cha.*",
      "P'X, my local friend, always had his own unique way of saying my name, owing to the Thai accent.",
      ">\"Err a little bit. You have the cards?\"",
      "I found myself standing outside the front door of his family home, an area bearing semblance of an outdoor porch. The space was vast, covered by a low roof to shade from Thailand's unforgiving sun. Tables and chairs scattered all around, his family members moving about. We were at his vacation home. His family from all over gathered here in Khao Yai for a reunion, and he kindly invited me along with some other Singaporean friends to their home in Khao Yai. I found myself across the porch to where P'X was standing at a makeshift table. Glancing down, the table was littered with cards and cups, one for each of the aunties seated around the table. They were all looking up at me now. A mixture of curiosity and anticipation on their faces.",
      ">\"Sawadee ka, my name is Ayesha\"",
      "I smiled and greeted them with a slight bow. Respect was a big thing in Thailand, and I always made a point to show respect, especially towards elders.",
      ">\"I-cha! X friend! Welcome. Come sit na!\"",
      "They smiled back and tapped on an empty chair, beckoning me to sit. I found myself playing poker with them well into the night. Despite the language barrier, the friendly gamble served well enough as common ground. Laughing and talking over the game, they seemed more than content in the heat of the moment, playing poker on the lopsided table. A rickety set-up that contributed to an even better atmosphere. I looked up to see some people gathered around what seemed to be a grill. They were fanning it the old-school way whilst another set up an electric fan. Similarly, they were also laughing and drinking. It was a simple, refreshing atmosphere to say the least.",
      "Further down towards the house gates lay an open area, where we later on sit around in a circle, on our camping chairs. We sat there talking about trivial things I don't even remember now. But what I do remember, is looking up at the sky to see it littered with stars. I've never seen so many of them packed together so closely before. I remember my gaze staying plastered on the sky as I relished in the moment. My local friends and their family opened their home to me,  treated me as their own. Made sure I was comfortable. I realised that my heart couldn't be fuller, sitting on an old chair that could barely hold my weight, eating skewers, drinking from $1 cans with foreign music in the background. At that point, I too was content in the simplicity of it all.",
      "Khao Yai was one of my most memorable places in Thailand not because it boasted the most beautiful sceneries or had the most extravagant culture. I have laid eyes on more novel attractions, more remarkable waterfalls, grander mountains. Yet, Khao Yai retains a soft spot in my heart, all because of the people I experienced it with. My local friends proudly showed me around. Drove us in questionable vehicles (with my friend managing to fall off whilst we were moving. oops.) Little Thai tidbits of culture and language every now and then. Even their family would jump in to try and teach us too. All with a warm smile on their face.",
      "*I-cha*. A completely butchered pronunciation of my name, but it didn't bother me at all. In fact, I marvelled at the fact that I was even lucky enough to be in such a position. A foreign country, foreign friends who have welcomed me into their family. A unique pronunciation —which the rest of his family adopted— that is now a token of kindness. Of hospitality. Of friendship that transcends beyond language barriers.",
      "Khop khun kha, P'X and P'Ung.",
      "![Project image](/writings/KY_1.jpg)"
    ],
    "markdown": ">\"I-cha!, you know how to play poker mai?\" \n\nMy head swivelled to the right. \n\n*I-cha.* \n\nP'X, my local friend, always had his own unique way of saying my name, owing to the Thai accent. \n\n>\"Err a little bit. You have the cards?\" \n\nI found myself standing outside the front door of his family home, an area bearing semblance of an outdoor porch. The space was vast, covered by a low roof to shade from Thailand's unforgiving sun. Tables and chairs scattered all around, his family members moving about. We were at his vacation home. His family from all over gathered here in Khao Yai for a reunion, and he kindly invited me along with some other Singaporean friends to their home in Khao Yai. I found myself across the porch to where P'X was standing at a makeshift table. Glancing down, the table was littered with cards and cups, one for each of the aunties seated around the table. They were all looking up at me now. A mixture of curiosity and anticipation on their faces. \n\n>\"Sawadee ka, my name is Ayesha\" \n\nI smiled and greeted them with a slight bow. Respect was a big thing in Thailand, and I always made a point to show respect, especially towards elders.   \n\n>\"I-cha! X friend! Welcome. Come sit na!\" \n\nThey smiled back and tapped on an empty chair, beckoning me to sit. I found myself playing poker with them well into the night. Despite the language barrier, the friendly gamble served well enough as common ground. Laughing and talking over the game, they seemed more than content in the heat of the moment, playing poker on the lopsided table. A rickety set-up that contributed to an even better atmosphere. I looked up to see some people gathered around what seemed to be a grill. They were fanning it the old-school way whilst another set up an electric fan. Similarly, they were also laughing and drinking. It was a simple, refreshing atmosphere to say the least. \n\nFurther down towards the house gates lay an open area, where we later on sit around in a circle, on our camping chairs. We sat there talking about trivial things I don't even remember now. But what I do remember, is looking up at the sky to see it littered with stars. I've never seen so many of them packed together so closely before. I remember my gaze staying plastered on the sky as I relished in the moment. My local friends and their family opened their home to me,  treated me as their own. Made sure I was comfortable. I realised that my heart couldn't be fuller, sitting on an old chair that could barely hold my weight, eating skewers, drinking from $1 cans with foreign music in the background. At that point, I too was content in the simplicity of it all.\n\nKhao Yai was one of my most memorable places in Thailand not because it boasted the most beautiful sceneries or had the most extravagant culture. I have laid eyes on more novel attractions, more remarkable waterfalls, grander mountains. Yet, Khao Yai retains a soft spot in my heart, all because of the people I experienced it with. My local friends proudly showed me around. Drove us in questionable vehicles (with my friend managing to fall off whilst we were moving. oops.) Little Thai tidbits of culture and language every now and then. Even their family would jump in to try and teach us too. All with a warm smile on their face. \n\n*I-cha*. A completely butchered pronunciation of my name, but it didn't bother me at all. In fact, I marvelled at the fact that I was even lucky enough to be in such a position. A foreign country, foreign friends who have welcomed me into their family. A unique pronunciation —which the rest of his family adopted— that is now a token of kindness. Of hospitality. Of friendship that transcends beyond language barriers.\n\nKhop khun kha, P'X and P'Ung.\n\n![Project image](/writings/KY_1.jpg)",
    "html": "<blockquote><p>&quot;I-cha!, you know how to play poker mai?&quot; </p></blockquote>\n<p>My head swivelled to the right.</p>\n<p><em>I-cha.</em></p>\n<p>P&#39;X, my local friend, always had his own unique way of saying my name, owing to the Thai accent.</p>\n<blockquote><p>&quot;Err a little bit. You have the cards?&quot; </p></blockquote>\n<p>I found myself standing outside the front door of his family home, an area bearing semblance of an outdoor porch. The space was vast, covered by a low roof to shade from Thailand&#39;s unforgiving sun. Tables and chairs scattered all around, his family members moving about. We were at his vacation home. His family from all over gathered here in Khao Yai for a reunion, and he kindly invited me along with some other Singaporean friends to their home in Khao Yai. I found myself across the porch to where P&#39;X was standing at a makeshift table. Glancing down, the table was littered with cards and cups, one for each of the aunties seated around the table. They were all looking up at me now. A mixture of curiosity and anticipation on their faces.</p>\n<blockquote><p>&quot;Sawadee ka, my name is Ayesha&quot; </p></blockquote>\n<p>I smiled and greeted them with a slight bow. Respect was a big thing in Thailand, and I always made a point to show respect, especially towards elders.</p>\n<blockquote><p>&quot;I-cha! X friend! Welcome. Come sit na!&quot; </p></blockquote>\n<p>They smiled back and tapped on an empty chair, beckoning me to sit. I found myself playing poker with them well into the night. Despite the language barrier, the friendly gamble served well enough as common ground. Laughing and talking over the game, they seemed more than content in the heat of the moment, playing poker on the lopsided table. A rickety set-up that contributed to an even better atmosphere. I looked up to see some people gathered around what seemed to be a grill. They were fanning it the old-school way whilst another set up an electric fan. Similarly, they were also laughing and drinking. It was a simple, refreshing atmosphere to say the least.</p>\n<p>Further down towards the house gates lay an open area, where we later on sit around in a circle, on our camping chairs. We sat there talking about trivial things I don&#39;t even remember now. But what I do remember, is looking up at the sky to see it littered with stars. I&#39;ve never seen so many of them packed together so closely before. I remember my gaze staying plastered on the sky as I relished in the moment. My local friends and their family opened their home to me,  treated me as their own. Made sure I was comfortable. I realised that my heart couldn&#39;t be fuller, sitting on an old chair that could barely hold my weight, eating skewers, drinking from $1 cans with foreign music in the background. At that point, I too was content in the simplicity of it all.</p>\n<p>Khao Yai was one of my most memorable places in Thailand not because it boasted the most beautiful sceneries or had the most extravagant culture. I have laid eyes on more novel attractions, more remarkable waterfalls, grander mountains. Yet, Khao Yai retains a soft spot in my heart, all because of the people I experienced it with. My local friends proudly showed me around. Drove us in questionable vehicles (with my friend managing to fall off whilst we were moving. oops.) Little Thai tidbits of culture and language every now and then. Even their family would jump in to try and teach us too. All with a warm smile on their face.</p>\n<p><em>I-cha</em>. A completely butchered pronunciation of my name, but it didn&#39;t bother me at all. In fact, I marvelled at the fact that I was even lucky enough to be in such a position. A foreign country, foreign friends who have welcomed me into their family. A unique pronunciation —which the rest of his family adopted— that is now a token of kindness. Of hospitality. Of friendship that transcends beyond language barriers.</p>\n<p>Khop khun kha, P&#39;X and P&#39;Ung.</p>\n<p><img src=\"/writings/KY_1.jpg\" alt=\"Project image\" /></p>"
  },
  {
    "id": "addie-larue",
    "slug": "addie-larue",
    "title": "The Invisible Life of Addie Larue",
    "excerpt": "My notes on one of my favourite books about perspective",
    "date": "2023-08-10",
    "category": "literature",
    "readTimeMinutes": 10,
    "content": [
      "## A short summary of the book \nThe story begins in 1714, France, when a woman named Addie Larue is tricked into making a deal with a dark god, Luc. He grants her immortality, but cursed to be **forgotten by everyone she meets**, thereby making her live an *invisible* life for years to come.",
      "For centuries Addie lives in solitude, with Luc visiting her on their 'anniversaries' to torment her into giving up her soul to him. However, Addie remains steadfast and grows to resent Luc for his constant manipulation. Eventually, Luc becomes the only constant in Addie's world of temporary connections. She finds herself looking forward to his visits, wrestling with feelings that toe between hatred and growing affection. Addie and Luc engage in a short romantic stint, which ends horribly. Luc does not visit her for years to come.",
      "Addie then meets Henry — the ++first person in 300 years who remembers her++. They fall in love, only for Addie to discover the truth: Henry too made a deal with Luc, and his time is running out.",
      "At first, Addie thinks Luc messed up by allowing the two of them to meet, only to find out that they played right into his plans. He wanted Addie to fall in love with Henry — and then be forced to grieve him when he dies in a few weeks. Luc orchestrated this entire plot to show Addie that mortal love is fragile and not worth the pain. He wanted Addie to run back to him.",
      "However, Luc's plan backfires. Addie remains stubborn and is instead all the more determined to make full use of her remaining time with Henry.",
      "On Henry's final night, Addie reveals that she made another deal with Luc to save Henry. The catch is that Addie must go with Luc. Henry is devastated, but Addie tells him she has lived long enough, and it is now Henry's turn to make the most of his. She makes Henry promise to remember her, before vanishing.",
      "> \"'You better live a good life, Henry Strauss' She begins to pull away, but his grip tightens. 'No'. She sighs, 'You've given me so much, Henry. But I need you to do one more thing.' Her forehead presses against his. '**I need you to remember.**'\"",
      "The story ends off with Addie walking by a bookstore, parallelism of where Henry and her first met. She observes a book: \"The invisible life of Addie Larue\" written by Henry. Though she was with Luc, inwardly she finds comfort in that she has tricked Luc the same way he tricked her all those years before: she did not tell him that she would be his forever — only up till he **no longer wanted her**, and she will do everything she can to make him stop wanting her. For now, Addie says nothing and only smiles as Luc pulls her into his arms.",
      "That is how the book ends, leaving the ending up for interpretation.",
      "## My thoughts",
      "From this, we can gather that in the end, Addie goes with Luc, and Henry writes a book about her titled 'The Invisible Life of Addie Larue'.",
      "I think it's a brilliant book. The ending may not sit well for others but in my opinion, it is clever and open-ended. I think many readers take for granted the revelation that Henry is the author of the book, and the world of possibilities it opens up.",
      "Because this makes it plausible that Addie's story is not told in total objectivity.",
      "## Henry's ending vs the Truth\nThe final chapter tells Addie's careful wording of her deal with Luc: \n> 'I'll be yours as long as you want me by your side'",
      "along with her supposed plan to make Luc hate her over time. In my opinion, this is merely Henry's interpretation of what had happened. This is his ending. The ending he wishes for.",
      "The realisation that the book is from Henry's perspective makes the reader ponder whether Addie's accounts were truly objective or if they were coloured with Henry's desires — with what he *wanted* to happen — he *wanted* Addie to be reluctant to go with Luc, that she only went with him in the name of saving Henry. He *wanted* to remember her as noble, as someone who reciprocated his love.",
      "*The truth is, Henry does not know at all*",
      "## Addie and Luc: More than Enemies?\nConsidering that Addie's story is told through Henry's lens, we can gather that Addie told Henry about her erratic relationship with Luc. Their relationship is explored in small fragments, from sensations of betrayal to fascination.",
      "This makes one wonder whether the short-lived bouts of romantic interest for Luc sprinkled few and far between throughout the book is truly insignificant — or if it is instead just a projection of what Henry *wants* it to be.",
      "Luc is humanised more and more as the story unfolds. He became capable of love for Addie, with his regular visits, and even admits to enjoying her company. Addie, in turn, also wonders about her feelings for Luc.",
      "The book shows Addie trying to convince herself it is not love. Then again, I think this is justified. Given their tumultous connection over 300 years, the line between love and obsession can be easily blurred. However, one can also interpret it as Addie denying it so fiercely because deep down she knows she caught intense feelings for him, feelings that could even be much stronger than those for Henry.",
      "## A Happy Ending in Disguise?\nIn the book Addie admits that she is no longer human. By extension, does that mean she is no longer capable of *human* love? Well, after centuries of immortality, her perspective has definitely shifted. Maybe Luc is the only one truly capable of understanding her.",
      "If that is the case, maybe her ending with Luc isn't tragic at all. She gets freedom from loneliness, a partnership with someone who matches her in wit, cunning and immortality. But since the book is told in Henry's point of view, it makes sense to end it off with Addie's vengeance and hatred for Luc.",
      "For Henry, it is tragic. For Addie, it could be liberation, with a hint of danger.",
      "## Why I Love the Ending\nThe ending of the book is thought-provoking and that's what I love about it. Schwab leaves us to piece together our own version of events from the book's tiny cues and interpretations of the characters' motives.",
      "You could take the ending purely as it is from Henry's perspective, reading a story of loss, darkness and self-sacrifice. On the other hand, you can also see it as a story of freedom, manipulation and unexpected companionship.",
      "The ending is an incredible interplay of perspective and loss. But I personally think that the main point of Addie's story was never about who won and who lost, but about how we *choose* to remember her — and the 'truths' we tell ourselves to make the ending feel complete."
    ],
    "markdown": "## A short summary of the book \nThe story begins in 1714, France, when a woman named Addie Larue is tricked into making a deal with a dark god, Luc. He grants her immortality, but cursed to be **forgotten by everyone she meets**, thereby making her live an *invisible* life for years to come. \n\nFor centuries Addie lives in solitude, with Luc visiting her on their 'anniversaries' to torment her into giving up her soul to him. However, Addie remains steadfast and grows to resent Luc for his constant manipulation. Eventually, Luc becomes the only constant in Addie's world of temporary connections. She finds herself looking forward to his visits, wrestling with feelings that toe between hatred and growing affection. Addie and Luc engage in a short romantic stint, which ends horribly. Luc does not visit her for years to come. \n\nAddie then meets Henry — the ++first person in 300 years who remembers her++. They fall in love, only for Addie to discover the truth: Henry too made a deal with Luc, and his time is running out.\n\nAt first, Addie thinks Luc messed up by allowing the two of them to meet, only to find out that they played right into his plans. He wanted Addie to fall in love with Henry — and then be forced to grieve him when he dies in a few weeks. Luc orchestrated this entire plot to show Addie that mortal love is fragile and not worth the pain. He wanted Addie to run back to him. \n\nHowever, Luc's plan backfires. Addie remains stubborn and is instead all the more determined to make full use of her remaining time with Henry. \n\nOn Henry's final night, Addie reveals that she made another deal with Luc to save Henry. The catch is that Addie must go with Luc. Henry is devastated, but Addie tells him she has lived long enough, and it is now Henry's turn to make the most of his. She makes Henry promise to remember her, before vanishing.\n\n> \"'You better live a good life, Henry Strauss' She begins to pull away, but his grip tightens. 'No'. She sighs, 'You've given me so much, Henry. But I need you to do one more thing.' Her forehead presses against his. '**I need you to remember.**'\"\n\nThe story ends off with Addie walking by a bookstore, parallelism of where Henry and her first met. She observes a book: \"The invisible life of Addie Larue\" written by Henry. Though she was with Luc, inwardly she finds comfort in that she has tricked Luc the same way he tricked her all those years before: she did not tell him that she would be his forever — only up till he **no longer wanted her**, and she will do everything she can to make him stop wanting her. For now, Addie says nothing and only smiles as Luc pulls her into his arms. \n\nThat is how the book ends, leaving the ending up for interpretation.\n\n## My thoughts\n\nFrom this, we can gather that in the end, Addie goes with Luc, and Henry writes a book about her titled 'The Invisible Life of Addie Larue'. \n\nI think it's a brilliant book. The ending may not sit well for others but in my opinion, it is clever and open-ended. I think many readers take for granted the revelation that Henry is the author of the book, and the world of possibilities it opens up.\n\nBecause this makes it plausible that Addie's story is not told in total objectivity.\n\n## Henry's ending vs the Truth\nThe final chapter tells Addie's careful wording of her deal with Luc: \n> 'I'll be yours as long as you want me by your side'\n\nalong with her supposed plan to make Luc hate her over time. In my opinion, this is merely Henry's interpretation of what had happened. This is his ending. The ending he wishes for.\n\nThe realisation that the book is from Henry's perspective makes the reader ponder whether Addie's accounts were truly objective or if they were coloured with Henry's desires — with what he *wanted* to happen — he *wanted* Addie to be reluctant to go with Luc, that she only went with him in the name of saving Henry. He *wanted* to remember her as noble, as someone who reciprocated his love.\n\n*The truth is, Henry does not know at all* \n\n## Addie and Luc: More than Enemies?\nConsidering that Addie's story is told through Henry's lens, we can gather that Addie told Henry about her erratic relationship with Luc. Their relationship is explored in small fragments, from sensations of betrayal to fascination.\n\nThis makes one wonder whether the short-lived bouts of romantic interest for Luc sprinkled few and far between throughout the book is truly insignificant — or if it is instead just a projection of what Henry *wants* it to be. \n\nLuc is humanised more and more as the story unfolds. He became capable of love for Addie, with his regular visits, and even admits to enjoying her company. Addie, in turn, also wonders about her feelings for Luc. \n\nThe book shows Addie trying to convince herself it is not love. Then again, I think this is justified. Given their tumultous connection over 300 years, the line between love and obsession can be easily blurred. However, one can also interpret it as Addie denying it so fiercely because deep down she knows she caught intense feelings for him, feelings that could even be much stronger than those for Henry. \n\n## A Happy Ending in Disguise?\nIn the book Addie admits that she is no longer human. By extension, does that mean she is no longer capable of *human* love? Well, after centuries of immortality, her perspective has definitely shifted. Maybe Luc is the only one truly capable of understanding her. \n\nIf that is the case, maybe her ending with Luc isn't tragic at all. She gets freedom from loneliness, a partnership with someone who matches her in wit, cunning and immortality. But since the book is told in Henry's point of view, it makes sense to end it off with Addie's vengeance and hatred for Luc. \n\nFor Henry, it is tragic. For Addie, it could be liberation, with a hint of danger.\n\n## Why I Love the Ending\nThe ending of the book is thought-provoking and that's what I love about it. Schwab leaves us to piece together our own version of events from the book's tiny cues and interpretations of the characters' motives.\n\nYou could take the ending purely as it is from Henry's perspective, reading a story of loss, darkness and self-sacrifice. On the other hand, you can also see it as a story of freedom, manipulation and unexpected companionship. \n\nThe ending is an incredible interplay of perspective and loss. But I personally think that the main point of Addie's story was never about who won and who lost, but about how we *choose* to remember her — and the 'truths' we tell ourselves to make the ending feel complete.",
    "html": "<h2>A short summary of the book </h2>\n<p>The story begins in 1714, France, when a woman named Addie Larue is tricked into making a deal with a dark god, Luc. He grants her immortality, but cursed to be <strong>forgotten by everyone she meets</strong>, thereby making her live an <em>invisible</em> life for years to come.</p>\n<p>For centuries Addie lives in solitude, with Luc visiting her on their &#39;anniversaries&#39; to torment her into giving up her soul to him. However, Addie remains steadfast and grows to resent Luc for his constant manipulation. Eventually, Luc becomes the only constant in Addie&#39;s world of temporary connections. She finds herself looking forward to his visits, wrestling with feelings that toe between hatred and growing affection. Addie and Luc engage in a short romantic stint, which ends horribly. Luc does not visit her for years to come.</p>\n<p>Addie then meets Henry — the <u>first person in 300 years who remembers her</u>. They fall in love, only for Addie to discover the truth: Henry too made a deal with Luc, and his time is running out.</p>\n<p>At first, Addie thinks Luc messed up by allowing the two of them to meet, only to find out that they played right into his plans. He wanted Addie to fall in love with Henry — and then be forced to grieve him when he dies in a few weeks. Luc orchestrated this entire plot to show Addie that mortal love is fragile and not worth the pain. He wanted Addie to run back to him.</p>\n<p>However, Luc&#39;s plan backfires. Addie remains stubborn and is instead all the more determined to make full use of her remaining time with Henry.</p>\n<p>On Henry&#39;s final night, Addie reveals that she made another deal with Luc to save Henry. The catch is that Addie must go with Luc. Henry is devastated, but Addie tells him she has lived long enough, and it is now Henry&#39;s turn to make the most of his. She makes Henry promise to remember her, before vanishing.</p>\n<blockquote><p>&quot;&#39;You better live a good life, Henry Strauss&#39; She begins to pull away, but his grip tightens. &#39;No&#39;. She sighs, &#39;You&#39;ve given me so much, Henry. But I need you to do one more thing.&#39; Her forehead presses against his. &#39;<strong>I need you to remember.</strong>&#39;&quot;</p></blockquote>\n<p>The story ends off with Addie walking by a bookstore, parallelism of where Henry and her first met. She observes a book: &quot;The invisible life of Addie Larue&quot; written by Henry. Though she was with Luc, inwardly she finds comfort in that she has tricked Luc the same way he tricked her all those years before: she did not tell him that she would be his forever — only up till he <strong>no longer wanted her</strong>, and she will do everything she can to make him stop wanting her. For now, Addie says nothing and only smiles as Luc pulls her into his arms.</p>\n<p>That is how the book ends, leaving the ending up for interpretation.</p>\n<h2>My thoughts</h2>\n<p>From this, we can gather that in the end, Addie goes with Luc, and Henry writes a book about her titled &#39;The Invisible Life of Addie Larue&#39;.</p>\n<p>I think it&#39;s a brilliant book. The ending may not sit well for others but in my opinion, it is clever and open-ended. I think many readers take for granted the revelation that Henry is the author of the book, and the world of possibilities it opens up.</p>\n<p>Because this makes it plausible that Addie&#39;s story is not told in total objectivity.</p>\n<h2>Henry&#39;s ending vs the Truth</h2>\n<p>The final chapter tells Addie&#39;s careful wording of her deal with Luc:</p>\n<blockquote><p>&#39;I&#39;ll be yours as long as you want me by your side&#39;</p></blockquote>\n<p>along with her supposed plan to make Luc hate her over time. In my opinion, this is merely Henry&#39;s interpretation of what had happened. This is his ending. The ending he wishes for.</p>\n<p>The realisation that the book is from Henry&#39;s perspective makes the reader ponder whether Addie&#39;s accounts were truly objective or if they were coloured with Henry&#39;s desires — with what he <em>wanted</em> to happen — he <em>wanted</em> Addie to be reluctant to go with Luc, that she only went with him in the name of saving Henry. He <em>wanted</em> to remember her as noble, as someone who reciprocated his love.</p>\n<p><em>The truth is, Henry does not know at all</em></p>\n<h2>Addie and Luc: More than Enemies?</h2>\n<p>Considering that Addie&#39;s story is told through Henry&#39;s lens, we can gather that Addie told Henry about her erratic relationship with Luc. Their relationship is explored in small fragments, from sensations of betrayal to fascination.</p>\n<p>This makes one wonder whether the short-lived bouts of romantic interest for Luc sprinkled few and far between throughout the book is truly insignificant — or if it is instead just a projection of what Henry <em>wants</em> it to be.</p>\n<p>Luc is humanised more and more as the story unfolds. He became capable of love for Addie, with his regular visits, and even admits to enjoying her company. Addie, in turn, also wonders about her feelings for Luc.</p>\n<p>The book shows Addie trying to convince herself it is not love. Then again, I think this is justified. Given their tumultous connection over 300 years, the line between love and obsession can be easily blurred. However, one can also interpret it as Addie denying it so fiercely because deep down she knows she caught intense feelings for him, feelings that could even be much stronger than those for Henry.</p>\n<h2>A Happy Ending in Disguise?</h2>\n<p>In the book Addie admits that she is no longer human. By extension, does that mean she is no longer capable of <em>human</em> love? Well, after centuries of immortality, her perspective has definitely shifted. Maybe Luc is the only one truly capable of understanding her.</p>\n<p>If that is the case, maybe her ending with Luc isn&#39;t tragic at all. She gets freedom from loneliness, a partnership with someone who matches her in wit, cunning and immortality. But since the book is told in Henry&#39;s point of view, it makes sense to end it off with Addie&#39;s vengeance and hatred for Luc.</p>\n<p>For Henry, it is tragic. For Addie, it could be liberation, with a hint of danger.</p>\n<h2>Why I Love the Ending</h2>\n<p>The ending of the book is thought-provoking and that&#39;s what I love about it. Schwab leaves us to piece together our own version of events from the book&#39;s tiny cues and interpretations of the characters&#39; motives.</p>\n<p>You could take the ending purely as it is from Henry&#39;s perspective, reading a story of loss, darkness and self-sacrifice. On the other hand, you can also see it as a story of freedom, manipulation and unexpected companionship.</p>\n<p>The ending is an incredible interplay of perspective and loss. But I personally think that the main point of Addie&#39;s story was never about who won and who lost, but about how we <em>choose</em> to remember her — and the &#39;truths&#39; we tell ourselves to make the ending feel complete.</p>"
  }
];

export function getWritingBySlug(slug) {
  return writings.find((w) => w.slug === slug);
}
